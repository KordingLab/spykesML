{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the MLencoding class\n",
    "\n",
    "This is a tutorial of how to use our MLencoding package to build encoding models a predict spikes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load encoding package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from MLencoding import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data\n",
    "Below we load a dataset available on CRCNS: a [Macaque M1](http://crcns.org/data-sets/movements/dream/downloading-dream) (from [Stevenston et al. 2011](http://jn.physiology.org/content/106/2/764.short)).\n",
    "\n",
    "The data has been organized in Matlab into neat arrays for easy loading here.\n",
    "\n",
    "We will soon want a single numpy array representing the external covariates, and a single numpy vector representing the neural response. The data array X will be of dimensions (n, p), where n is the number of time bins and p is the number of covariates, and the response y will be of dimensions (n, ) . We use pandas as an intermediate tool for data organizing, but it's really not necessary - if using your own data just wrangle it into numpy arrays of proper dimension.\n",
    "\n",
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1_imported = scipy.io.loadmat('../data/m1_stevenson_2011.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Covariates\n",
    "\n",
    "Pull into pandas dataframe. This allows us to easily access covariates by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>handPos_x</th>\n",
       "      <th>handPos_y</th>\n",
       "      <th>handVel_x</th>\n",
       "      <th>handVel_y</th>\n",
       "      <th>velDir</th>\n",
       "      <th>cos_velDir</th>\n",
       "      <th>sin_velDir</th>\n",
       "      <th>speed</th>\n",
       "      <th>cos_PosDir</th>\n",
       "      <th>sin_PosDir</th>\n",
       "      <th>radial_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.591</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>-0.303636</td>\n",
       "      <td>-0.011201</td>\n",
       "      <td>-0.006237</td>\n",
       "      <td>-2.633523</td>\n",
       "      <td>-0.873685</td>\n",
       "      <td>-0.486491</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>0.303650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.641</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>-0.303869</td>\n",
       "      <td>-0.010743</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-3.064245</td>\n",
       "      <td>-0.997010</td>\n",
       "      <td>-0.077271</td>\n",
       "      <td>0.010775</td>\n",
       "      <td>0.007437</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>0.303877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.691</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>-0.303631</td>\n",
       "      <td>0.017680</td>\n",
       "      <td>0.012094</td>\n",
       "      <td>0.599956</td>\n",
       "      <td>0.825360</td>\n",
       "      <td>0.564606</td>\n",
       "      <td>0.021420</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>0.303641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.741</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>-0.302399</td>\n",
       "      <td>0.044667</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.713933</td>\n",
       "      <td>0.755792</td>\n",
       "      <td>0.654812</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.013258</td>\n",
       "      <td>-0.999912</td>\n",
       "      <td>0.302426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.791</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>-0.300673</td>\n",
       "      <td>0.042202</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>0.383375</td>\n",
       "      <td>0.927408</td>\n",
       "      <td>0.374053</td>\n",
       "      <td>0.045505</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>-0.999775</td>\n",
       "      <td>0.300741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  handPos_x  handPos_y  handVel_x  handVel_y    velDir  cos_velDir  \\\n",
       "0  12.591   0.002905  -0.303636  -0.011201  -0.006237 -2.633523   -0.873685   \n",
       "1  12.641   0.002260  -0.303869  -0.010743  -0.000833 -3.064245   -0.997010   \n",
       "2  12.691   0.002399  -0.303631   0.017680   0.012094  0.599956    0.825360   \n",
       "3  12.741   0.004010  -0.302399   0.044667   0.038700  0.713933    0.755792   \n",
       "4  12.791   0.006386  -0.300673   0.042202   0.017021  0.383375    0.927408   \n",
       "\n",
       "   sin_velDir     speed  cos_PosDir  sin_PosDir  radial_Pos  \n",
       "0   -0.486491  0.012820    0.009568   -0.999954    0.303650  \n",
       "1   -0.077271  0.010775    0.007437   -0.999972    0.303877  \n",
       "2    0.564606  0.021420    0.007900   -0.999969    0.303641  \n",
       "3    0.654812  0.059100    0.013258   -0.999912    0.302426  \n",
       "4    0.374053  0.045505    0.021233   -0.999775    0.300741  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['time'] =  m1_imported['time'][0]\n",
    "data['handPos_x'] =  m1_imported['handPos'][0]\n",
    "data['handPos_y'] =  m1_imported['handPos'][1]\n",
    "data['handVel_x'] =  m1_imported['handVel'][0]\n",
    "data['handVel_y'] =  m1_imported['handVel'][1]\n",
    "\n",
    "#### Compute more covariates/features\n",
    "\n",
    "#These will be used as the 'engineered' features for improving the GLM's performance.\n",
    "\n",
    "data['velDir'] = np.arctan2(data['handVel_y'], data['handVel_x'])\n",
    "data['cos_velDir'] = np.cos(data['velDir'])\n",
    "data['sin_velDir'] = np.sin(data['velDir'])\n",
    "data['speed'] = np.sqrt(data['handVel_x'].values**2+data['handVel_y'].values**2)\n",
    "r = np.arctan2(data['handPos_y'], data['handPos_x'])\n",
    "data['cos_PosDir'] = np.cos(r)\n",
    "data['sin_PosDir'] = np.sin(r)\n",
    "data['radial_Pos'] = np.sqrt(data['handPos_x'].values**2+data['handPos_y'].values**2)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Making an encoding model\n",
    "\n",
    "We instantiate the object like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_model = MLencoding(tunemodel = 'glm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then train it on some data. Let's go for 3/4 of the data we have for some neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neuron_n = 1\n",
    "\n",
    "X = data[['handPos_x','handPos_y','handVel_x','handVel_y']].values\n",
    "y = m1_imported['spikes'][neuron_n]\n",
    "\n",
    "n_samples = X.shape[0]\n",
    "threefourths = int(n_samples*3/4)\n",
    "\n",
    "X_train = X[:threefourths,:]\n",
    "y_train = y[:threefourths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we train the model\n",
    "\n",
    "glm_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the neural response on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = X[threefourths:,:]\n",
    "y_test = y[threefourths:]\n",
    "\n",
    "y_hat = glm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do? We can score this prediction with the class's internal function 'poisson_pseudoR2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0625913964434\n"
     ]
    }
   ],
   "source": [
    "# The 'null model' we measure against is the mean of the train dataset. \n",
    "y_null = np.mean(y_train)\n",
    "\n",
    "pr2_glm = glm_model.poisson_pseudoR2(y_test, y_hat, y_null)\n",
    "print(pr2_glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "Let's now obtain the predictions and scores of 10-fold cross-validation for a GLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...runnning cv-fold 1 of 10\n",
      "pR2:  0.0488023178838\n",
      "...runnning cv-fold 2 of 10\n",
      "pR2:  0.0434830590622\n",
      "...runnning cv-fold 3 of 10\n",
      "pR2:  0.0513488923378\n",
      "...runnning cv-fold 4 of 10\n",
      "pR2:  0.0521074580784\n",
      "...runnning cv-fold 5 of 10\n",
      "pR2:  0.0449312912574\n",
      "...runnning cv-fold 6 of 10\n",
      "pR2:  0.062685886475\n",
      "...runnning cv-fold 7 of 10\n",
      "pR2:  0.0459586387009\n",
      "...runnning cv-fold 8 of 10\n",
      "pR2:  0.0578141187789\n",
      "...runnning cv-fold 9 of 10\n",
      "pR2:  0.0523027349251\n",
      "...runnning cv-fold 10 of 10\n",
      "pR2:  0.0496125678667\n",
      "pR2_cv: 0.050905 (+/- 0.001765)\n"
     ]
    }
   ],
   "source": [
    "Y_hat, PR2s = glm_model.fit_cv(X,y, n_cv = 10, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Other methods: neural networks, random forest, XGBoost\n",
    "\n",
    "Using other encoding models is as simple as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_model = MLencoding(tunemodel='feedforward_nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...runnning cv-fold 1 of 10\n",
      "pR2:  0.0973511536366\n",
      "...runnning cv-fold 2 of 10\n",
      "pR2:  0.105358255116\n",
      "...runnning cv-fold 3 of 10\n",
      "pR2:  0.105960770234\n",
      "...runnning cv-fold 4 of 10\n",
      "pR2:  0.118384046484\n",
      "...runnning cv-fold 5 of 10\n",
      "pR2:  0.0824833296985\n",
      "...runnning cv-fold 6 of 10\n",
      "pR2:  0.111601716963\n",
      "...runnning cv-fold 7 of 10\n",
      "pR2:  0.11344632257\n",
      "...runnning cv-fold 8 of 10\n",
      "pR2:  0.109179061213\n",
      "...runnning cv-fold 9 of 10\n",
      "pR2:  0.112530046581\n",
      "...runnning cv-fold 10 of 10\n",
      "pR2:  0.0907163987897\n",
      "pR2_cv: 0.104701 (+/- 0.003373)\n"
     ]
    }
   ],
   "source": [
    "Y_hat, PR2s = nn_model.fit_cv(X,y, n_cv = 10, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting spikes using spike or covariate history\n",
    "\n",
    "MLencoding supports models that also use previous covariate values to predict the current spike rate. Spike history is also supported.\n",
    "\n",
    "When you instantiate a model with the `spike_history=True` or `cov_history=True` keywords, all future calls to `fit`, `predict`, and `fit_cv` will automatically construct a new covariate matrix with additional columns. These columns represent the covariate history. This matrix is then used for fitting.\n",
    "\n",
    "Currently, covariate history columns are raised cosine basis functions. You can define how many temporal basis you want with `n_filters`, which will span the interval [0, `max_time`]. Times are measured in milliseconds. In order to perform this calculation, the model needs to know how many milliseconds are in each time bin. (Set this with `window`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_history = MLencoding(tunemodel = 'xgboost',\n",
    "                         cov_history = False, spike_history=True, # We can choose!\n",
    "                         window = 50, #this dataset has 50ms time bins\n",
    "                         n_filters = 2,\n",
    "                         max_time = 250 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...runnning cv-fold 0 of 10\n",
      "pR2:  0.172896381616\n",
      "...runnning cv-fold 1 of 10\n",
      "pR2:  0.151629755677\n",
      "...runnning cv-fold 2 of 10\n",
      "pR2:  0.183958679349\n",
      "...runnning cv-fold 3 of 10\n",
      "pR2:  0.149697611433\n",
      "...runnning cv-fold 4 of 10\n",
      "pR2:  0.127944114605\n",
      "...runnning cv-fold 5 of 10\n",
      "pR2:  0.146583568384\n",
      "...runnning cv-fold 6 of 10\n",
      "pR2:  0.227747587776\n",
      "...runnning cv-fold 7 of 10\n",
      "pR2:  0.265500709309\n",
      "...runnning cv-fold 8 of 10\n",
      "pR2:  0.275622248323\n",
      "...runnning cv-fold 9 of 10\n",
      "pR2:  0.266005528721\n",
      "pR2_cv: 0.196759 (+/- 0.017011)\n"
     ]
    }
   ],
   "source": [
    "xgb_history.fit_cv(X,y, verbose = 2, continuous_folds = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a version that uses spike history with random folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...runnning cv-fold 1 of 10\n",
      "pR2:  0.172660664684\n",
      "...runnning cv-fold 2 of 10\n",
      "pR2:  0.201177093824\n",
      "...runnning cv-fold 3 of 10\n",
      "pR2:  0.181089793866\n",
      "...runnning cv-fold 4 of 10\n",
      "pR2:  0.148885335305\n",
      "...runnning cv-fold 5 of 10\n",
      "pR2:  0.183087263289\n",
      "...runnning cv-fold 6 of 10\n",
      "pR2:  0.17288721494\n",
      "...runnning cv-fold 7 of 10\n",
      "pR2:  0.130874947193\n",
      "...runnning cv-fold 8 of 10\n",
      "pR2:  0.175744079298\n",
      "...runnning cv-fold 9 of 10\n",
      "pR2:  0.149755921527\n",
      "...runnning cv-fold 10 of 10\n",
      "pR2:  0.0676141844825\n",
      "pR2_cv: 0.158378 (+/- 0.011328)\n"
     ]
    }
   ],
   "source": [
    "# First we need to set n_every > max_time/window. \n",
    "xgb_history_rand = MLencoding(tunemodel = 'xgboost',\n",
    "                         cov_history = False, spike_history=True,\n",
    "                         window = 50, \n",
    "                         n_filters = 2,\n",
    "                         max_time = 250, n_every = 6 )\n",
    "\n",
    "xgb_history_rand.fit_cv(X,y, verbose = 2, continuous_folds = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting an LSTM\n",
    "\n",
    "There's nothing special about fitting an LSTM in our implementation. Just be sure to set `spike_history=True` and `cov_history = True`, and to use continuous CV folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = MLencoding(tunemodel = 'lstm',\n",
    "                         cov_history = True, spike_history=True, # We can choose!\n",
    "                         window = 50, #this dataset has 50ms time bins\n",
    "                         n_filters = 4,\n",
    "                         max_time = 250 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...runnning cv-fold 0 of 10\n",
      "pR2:  0.178190232035\n",
      "...runnning cv-fold 1 of 10\n",
      "pR2:  0.169885240103\n",
      "...runnning cv-fold 2 of 10\n",
      "pR2:  0.176461553019\n",
      "...runnning cv-fold 3 of 10\n",
      "pR2:  0.161520848555\n",
      "...runnning cv-fold 4 of 10\n",
      "pR2:  0.132098223238\n",
      "...runnning cv-fold 5 of 10\n",
      "pR2:  0.149307415463\n",
      "...runnning cv-fold 6 of 10\n",
      "pR2:  0.246421820011\n",
      "...runnning cv-fold 7 of 10\n",
      "pR2:  0.269467384959\n",
      "...runnning cv-fold 8 of 10\n",
      "pR2:  0.276576452182\n",
      "...runnning cv-fold 9 of 10\n",
      "pR2:  0.281433609311\n",
      "pR2_cv: 0.204136 (+/- 0.017292)\n"
     ]
    }
   ],
   "source": [
    "lstm.fit_cv(X,y, verbose = 2, continuous_folds = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and setting model parameters\n",
    "To get the current set of parameters, we can either run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': 0.5, 'l1': 0.0, 'l2': 0.0, 'n1': 1980, 'n2': 18}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.params\n",
    "# or nn_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the parameters with the `set_params` method. This method takes a dictionary, which update the current set of parameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_model.set_params({'dropout':0.3})\n",
    "nn_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization using hyperopt\n",
    "\n",
    "We might not want the default parameters. Here's how to set some better ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, hp, Trials, tpe, STATUS_OK\n",
    "\n",
    "# Makes sure these are in nn_models.params, otherwise you'll get a key error\n",
    "space4rf = {\n",
    "    'dropout': hp.uniform('dropout', 0., 0.6),\n",
    "    'n1': hp.uniform('n1', 2,128),\n",
    "    'n2': hp.uniform('n2', 1,15),\n",
    "}\n",
    "\n",
    "#object that holds iteration results\n",
    "trials = Trials()\n",
    "\n",
    "#define model\n",
    "nn_model = MLencoding(tunemodel='feedforward_nn')\n",
    "\n",
    "#function to minimize\n",
    "def fnc(params):\n",
    "    \n",
    "    # make sure parameters are integers that need to be. \n",
    "    params['n1'] = int(params['n1'])\n",
    "    params['n2'] = int(params['n2'])\n",
    "\n",
    "    nn_model.set_params(params)\n",
    "    \n",
    "    # Remember that X and y have been defined above.\n",
    "    Y_hat, PR2s = nn_model.fit_cv(X,y, n_cv = 5, verbose = 0)\n",
    "\n",
    "    # return negative since hyperopt always minimizes the function\n",
    "    return -np.mean(pseudo_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that our neuron #1 is a held-out neuron for parameter optimization. Let's optimize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hyperoptBest = fmin(fnc, space4rf, algo=tpe.suggest, max_evals=50, trials=trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining your own models\n",
    "\n",
    "The `MLencoding` class is flexible and can be used with predefined models as long as they have `fit` and `predict` methods.\n",
    "\n",
    "Let's build a different type of neural network, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_model = Sequential()\n",
    "my_model.add(Dense(100, input_dim=np.shape(X)[1], init='glorot_normal',\n",
    "            activation='relu',))\n",
    "my_model.add(Dense(1,activation='softplus'))\n",
    "optim = Nadam()\n",
    "my_model.compile(loss='poisson', optimizer=optim,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_enc = MLencoding(tunemodel = my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...runnning cv-fold 1 of 5\n",
      "pR2:  -0.00401729001754\n",
      "...runnning cv-fold 2 of 5\n",
      "pR2:  -0.00440856722819\n",
      "...runnning cv-fold 3 of 5\n",
      "pR2:  -0.00344133554292\n",
      "...runnning cv-fold 4 of 5\n",
      "pR2:  -0.000698628352245\n",
      "...runnning cv-fold 5 of 5\n",
      "pR2:  -0.00209311949187\n",
      "pR2_cv: -0.002932 (+/- 0.000610)\n"
     ]
    }
   ],
   "source": [
    "my_enc.fit_cv(X,y,n_cv=5,verbose=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model isn't great, but you see how it's possible. \n",
    "\n",
    "There are some limitations here, though. One thing I can think off the bat is that this Keras model won't work if we set `spike_history = True`, since that will change the shape of `X` and the shape of the input layer is hard-coded when we built this model. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
